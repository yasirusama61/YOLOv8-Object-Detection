# ü©∫ Thoracic Abnormality Detection: YOLOv8 and Faster R-CNN üñºÔ∏è

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red?logo=pytorch&logoColor=white)
![YOLOv8](https://img.shields.io/badge/YOLOv8-‚úîÔ∏è-green?logo=ultralytics)
![FasterRCNN](https://img.shields.io/badge/FasterRCNN-ResNet--50-orange)
![License](https://img.shields.io/badge/License-MIT-brightgreen)

This project leverages advanced object detection architectures to identify thoracic abnormalities in chest X-rays. We aim to compare **YOLOv8** (single-stage) and **Faster R-CNN** (two-stage) models, optimizing their performance for real-world medical diagnostics. ü©ª

## Project Overview

![Chest X-Ray Abnormality Detection Overview](results/task_overview.png)

---

## üéØ **Purpose of the Project**
Chest X-rays are a crucial diagnostic tool for thoracic diseases. This project seeks to:
- üîç **Train and Evaluate**: Develop models for detecting abnormalities like Consolidation, Nodule, and Pneumothorax.
- ‚öñÔ∏è **Compare Architectures**: Analyze YOLOv8 and Faster R-CNN in terms of speed, accuracy, and precision.
- üõ†Ô∏è **Optimize Performance**: Apply techniques like class-weighting, augmentation, and learning rate adjustment.
- üìä **Provide Insights**: Highlight the strengths and weaknesses of each architecture in real-world applications.

---

## üìÇ **Dataset Overview**
### Dataset: [ChestX-Det10](https://www.kaggle.com/datasets) 

The dataset includes 3,543 chest X-ray images annotated with bounding boxes for 10 thoracic abnormalities, including Nodule, Mass, and Pneumothorax. This project uses the ChestX-Det10 dataset, a subset of NIH ChestX-14.
The dataset includes chest X-rays annotated with bounding boxes for 10 thoracic abnormalities:
- **Classes**: 
  - Consolidation, Pneumothorax, Emphysema, Calcification, Nodule, Mass, Fracture, Effusion, Atelectasis, Fibrosis.
- **Statistics**:
  - Training Images: **3,001**
  - Testing Images: **1,000+**
  - Missing Data: **22.69% treated as background.**

---

## üõ†Ô∏è **Project Workflow**
1. **Data Preparation** üì¶
   - Organize the dataset into YOLO-compatible format (`images/`, `labels/`).
   - Convert annotations from `train.json` and `test.json` to YOLO format.
   - Handle missing data by treating unannotated images as background.
   
2. **Model Architectures** ü§ñ
   - **YOLOv8 (Single-Stage Detection)**:
     - Fast and lightweight, optimized for real-time applications.
   - **Faster R-CNN (Two-Stage Detection)**:
     - Accurate and reliable, with ResNet-50 backbone for feature extraction.
     
3. **Training Configuration** üèãÔ∏è‚Äç‚ôÄÔ∏è
   - Data augmentation: Mosaic, horizontal flipping, CutMix.
   - Optimizer: AdamW for YOLOv8, SGD for Faster R-CNN.
   - Custom class weighting for imbalance correction.

4. **Evaluation** üìä
   - Compare metrics like Precision, Recall, mAP@0.5, and mAP@0.5:0.95.

---

## Overview of Faster R-CNN üñºÔ∏è

Faster R-CNN is a state-of-the-art two-stage object detection framework designed for high accuracy in identifying objects within an image. Below is a detailed explanation of its architecture:

---

### üîë **Key Components**
- **Backbone**:
  - ResNet-50 with a Feature Pyramid Network (FPN) is used for extracting rich, multi-scale features from input images.
- **RPN (Region Proposal Network)**:
  - Proposes candidate regions in the image that may contain objects.
- **RoI Pooling**:
  - Aligns features from the proposed regions into a uniform size for further processing.
- **Prediction Heads**:
  - **Classification Head**: Predicts the object categories within the proposed regions.
  - **Bounding Box Regressor**: Refines the coordinates of bounding boxes for better localization.

---

### üõ†Ô∏è **Workflow**
1. **Input Image Processing**:
   - The input image is fed into the backbone for feature extraction.
2. **Feature Extraction (FPN)**:
   - Multi-scale features are generated by the FPN for different levels of abstraction.
3. **Region Proposal Network (RPN)**:
   - Generates candidate bounding boxes or "region proposals."
4. **RoI Pooling**:
   - Extracts fixed-size feature maps from each region proposal.
5. **Prediction**:
   - The extracted features are passed through fully connected layers to:
     - **Classify objects** within regions of interest.
     - **Refine bounding box coordinates** for better accuracy.


![Faster R-CNN Model Architecture Overview](results/faster_r_cnn.png)

This snapshot illustrates the general architecture of Faster R-CNN, including key components like the Feature Pyramid Network (FPN), Region Proposal Network (RPN), and prediction heads for classification and regression.

---

## üìä **Exploratory Data Analysis (EDA)**

### **1. Class Distribution**
The dataset contains imbalanced classes, as shown in the chart below. This highlights the importance of oversampling, augmentation, or WeightedRandomSampler techniques to manage minority classes effectively.

![Class Distribution](results/visualizations/class_distribution.png)

---

### **2. Bounding Box Distribution**
Analyzing bounding box dimensions helps uncover patterns that can inform preprocessing and augmentation strategies. Below are the width, height, and area distributions of the bounding boxes in the dataset:

#### **Bounding Box Width Distribution**
![Bounding Box Width](results/visualizations/bounding_box_width.png)

#### **Bounding Box Height Distribution**
![Bounding Box Height](results/visualizations/bounding_box_height.png)

#### **Bounding Box Area Distribution**
![Bounding Box Area](results/visualizations/bounding_box_area.png)

---
### **Key Insights from EDA**

1. **Class Distribution**:
   - The dataset shows significant class imbalance, with **Consolidation** and **Effusion** being the most common categories, while **Mass** and **Pneumothorax** are underrepresented.
   - This imbalance highlights the need for techniques like **oversampling**, **augmentation**, or **WeightedRandomSampler** to address model bias.

2. **Bounding Box Width, Height, and Area**:
   - **Width and Height**:
     - Most bounding boxes are small, with the majority having widths and heights under 200 pixels.
   - **Area**:
     - Bounding box areas are heavily skewed towards smaller regions, indicating that small abnormalities dominate the dataset.
   - These patterns suggest that the model must handle **small object detection** effectively, which may require **attention mechanisms** (e.g., CBAM) or **multi-scale feature maps** (e.g., FPN).

By addressing these challenges during preprocessing and model design, performance on challenging classes and smaller abnormalities can be significantly improved.

---

## üöÄ **How to Run the Project**
### 1Ô∏è. Clone the Repository
```bash
git clone https://github.com/yasirusama61/YOLOv8-Object-Detection.git
cd thoracic-abnormality-detection
```
### 2. Install dependencies:
```bash
pip install requirements.txt
```
## üõ†Ô∏è **Data Preparation**

### **Step 1: Convert Annotations to YOLO Format**  
üìÑ Use the following script to process `train.json` and `test.json`, converting them into YOLO-compatible annotations:

```bash
python scripts/convert_annotations.py
```
  This script:
  - Converts bounding box annotations to YOLO format (class_id x_center y_center width height).
  - Treats missing data (images without bounding boxes) as background by creating empty .txt files.

### **Step 2: Verify Dataset**
  Ensure the following structure:

  ```
  yolo_dataset/
  ‚îú‚îÄ‚îÄ images/
  ‚îÇ   ‚îú‚îÄ‚îÄ train/     # Training images
  ‚îÇ   ‚îú‚îÄ‚îÄ test/      # Testing images
  ‚îú‚îÄ‚îÄ labels/
  ‚îÇ   ‚îú‚îÄ‚îÄ train/     # YOLO format labels for training
  ‚îÇ   ‚îú‚îÄ‚îÄ test/      # YOLO format labels for testing
  ```
## üìä Results

### Faster R-CNN Metrics:
- **AP@25**: 0.62
- **AP@50**: 0.56
- **AP@75**: 0.48
- **Details**: Implemented CBAM attention mechanism and trained with ResNet-50 backbone. Performed well on larger abnormalities like Nodule but faced challenges with smaller regions like Mass.

## üñºÔ∏è **Detection Results**

### Faster R-CNN Detection Results
Below is a snapshot of the **Faster R-CNN** detection results on chest X-ray images. The model successfully identifies abnormalities such as Consolidation, Nodule, and Pneumothorax, leveraging a **ResNet-50 backbone** and the **ChestX-Det10 dataset**:

![Faster R-CNN Detection Results](results/visualizations/detection_results.png)

### Key Observations:
- **Red Bounding Boxes**: Detected abnormalities.
- **Yellow Labels**: Identified categories (e.g., Consolidation, Nodule).
- The model demonstrates high accuracy for larger abnormalities but faces challenges with smaller regions.

#### Performance Highlights:
- **mAP@50**: 0.56
- **AP@25**: 0.62
- Focused on achieving better detection for underrepresented classes (e.g., Mass, Pneumothorax) through class weighting and augmentation strategies.

### YOLOv8 Metrics:
- **Precision**: ~70%
- **Recall**: ~65%
- **mAP@50**: ~0.497
- **mAP@50-95**: ~0.271
- **Details**: Focused on speed and real-time application. Struggled with minority classes but performed robustly on larger, well-represented classes.

### Next Steps:
- Fine-tune both Faster R-CNN and YOLOv8 to address small-region abnormalities.
- Improve dataset balance for minority classes with advanced sampling techniques.

