# ğŸ©º Thoracic Abnormality Detection: YOLOv8 and Faster R-CNN ğŸ–¼ï¸

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red?logo=pytorch&logoColor=white)
![YOLOv8](https://img.shields.io/badge/YOLOv8-âœ”ï¸-green?logo=ultralytics)
![FasterRCNN](https://img.shields.io/badge/FasterRCNN-ResNet--50-orange)
![License](https://img.shields.io/badge/License-MIT-brightgreen)

This project leverages advanced object detection architectures to identify thoracic abnormalities in chest X-rays. We aim to compare **YOLOv8** (single-stage) and **Faster R-CNN** (two-stage) models, optimizing their performance for real-world medical diagnostics. ğŸ©»

## Project Overview

![Chest X-Ray Abnormality Detection Overview](results/task_overview.png)

---

## ğŸ¯ **Purpose of the Project**
Chest X-rays are a crucial diagnostic tool for thoracic diseases. This project seeks to:
- ğŸ” **Train and Evaluate**: Develop models for detecting abnormalities like Consolidation, Nodule, and Pneumothorax.
- âš–ï¸ **Compare Architectures**: Analyze YOLOv8 and Faster R-CNN in terms of speed, accuracy, and precision.
- ğŸ› ï¸ **Optimize Performance**: Apply techniques like class-weighting, augmentation, and learning rate adjustment.
- ğŸ“Š **Provide Insights**: Highlight the strengths and weaknesses of each architecture in real-world applications.

---

## ğŸ“‚ **Dataset Overview**
### Dataset: [ChestX-Det10](https://www.kaggle.com/datasets) 

The dataset includes 3,543 chest X-ray images annotated with bounding boxes for 10 thoracic abnormalities, including Nodule, Mass, and Pneumothorax. This project uses the ChestX-Det10 dataset, a subset of NIH ChestX-14.
The dataset includes chest X-rays annotated with bounding boxes for 10 thoracic abnormalities:
- **Classes**: 
  - Consolidation, Pneumothorax, Emphysema, Calcification, Nodule, Mass, Fracture, Effusion, Atelectasis, Fibrosis.
- **Statistics**:
  - Training Images: **3,001**
  - Testing Images: **1,000+**
  - Missing Data: **22.69% treated as background.**

---

## ğŸ› ï¸ **Project Workflow**
1. **Data Preparation** ğŸ“¦
   - Organize the dataset into YOLO-compatible format (`images/`, `labels/`).
   - Convert annotations from `train.json` and `test.json` to YOLO format.
   - Handle missing data by treating unannotated images as background.
   
2. **Model Architectures** ğŸ¤–
   - **YOLOv8 (Single-Stage Detection)**:
     - Fast and lightweight, optimized for real-time applications.
   - **Faster R-CNN (Two-Stage Detection)**:
     - Accurate and reliable, with ResNet-50 backbone for feature extraction.
     
3. **Training Configuration** ğŸ‹ï¸â€â™€ï¸
   - Data augmentation: Mosaic, horizontal flipping, CutMix.
   - Optimizer: AdamW for YOLOv8, SGD for Faster R-CNN.
   - Custom class weighting for imbalance correction.

4. **Evaluation** ğŸ“Š
   - Compare metrics like Precision, Recall, mAP@0.5, and mAP@0.5:0.95.

---

## Overview of Faster R-CNN ğŸ–¼ï¸

Faster R-CNN is a state-of-the-art two-stage object detection framework designed for high accuracy in identifying objects within an image. Below is a detailed explanation of its architecture:

---

### ğŸ”‘ **Key Components**
- **Backbone**:
  - ResNet-50 with a Feature Pyramid Network (FPN) is used for extracting rich, multi-scale features from input images.
- **RPN (Region Proposal Network)**:
  - Proposes candidate regions in the image that may contain objects.
- **RoI Pooling**:
  - Aligns features from the proposed regions into a uniform size for further processing.
- **Prediction Heads**:
  - **Classification Head**: Predicts the object categories within the proposed regions.
  - **Bounding Box Regressor**: Refines the coordinates of bounding boxes for better localization.

---

### ğŸ› ï¸ **Workflow**
1. **Input Image Processing**:
   - The input image is fed into the backbone for feature extraction.
2. **Feature Extraction (FPN)**:
   - Multi-scale features are generated by the FPN for different levels of abstraction.
3. **Region Proposal Network (RPN)**:
   - Generates candidate bounding boxes or "region proposals."
4. **RoI Pooling**:
   - Extracts fixed-size feature maps from each region proposal.
5. **Prediction**:
   - The extracted features are passed through fully connected layers to:
     - **Classify objects** within regions of interest.
     - **Refine bounding box coordinates** for better accuracy.


![Faster R-CNN Model Architecture Overview](results/faster_r_cnn.png)

This snapshot illustrates the general architecture of Faster R-CNN, including key components like the Feature Pyramid Network (FPN), Region Proposal Network (RPN), and prediction heads for classification and regression.

---

## ğŸ“Š **Exploratory Data Analysis (EDA)**

### **1. Class Distribution**
The dataset contains imbalanced classes, as shown in the chart below. This highlights the importance of oversampling, augmentation, or WeightedRandomSampler techniques to manage minority classes effectively.

![Class Distribution](results/visualizations/class_distribution.png)

---

### **2. Bounding Box Distribution**
Analyzing bounding box dimensions helps uncover patterns that can inform preprocessing and augmentation strategies. Below are the width, height, and area distributions of the bounding boxes in the dataset:

#### **Bounding Box Width Distribution**
![Bounding Box Width](results/visualizations/bounding_box_width.png)

#### **Bounding Box Height Distribution**
![Bounding Box Height](results/visualizations/bounding_box_height.png)

#### **Bounding Box Area Distribution**
![Bounding Box Area](results/visualizations/bounding_box_area.png)

---


## ğŸš€ **How to Run the Project**
### 1ï¸. Clone the Repository
```bash
git clone https://github.com/yasirusama61/YOLOv8-Object-Detection.git
cd thoracic-abnormality-detection
```
### 2. Install dependencies:
```bash
pip install ultralytics
```
## ğŸ› ï¸ **Data Preparation**

### **Step 1: Convert Annotations to YOLO Format**  
ğŸ“„ Use the following script to process `train.json` and `test.json`, converting them into YOLO-compatible annotations:

```bash
python scripts/convert_annotations.py
```
  This script:
  - Converts bounding box annotations to YOLO format (class_id x_center y_center width height).
  - Treats missing data (images without bounding boxes) as background by creating empty .txt files.

### **Step 2: Verify Dataset**
  Ensure the following structure:

  ```
  yolo_dataset/
  â”œâ”€â”€ images/
  â”‚   â”œâ”€â”€ train/     # Training images
  â”‚   â”œâ”€â”€ test/      # Testing images
  â”œâ”€â”€ labels/
  â”‚   â”œâ”€â”€ train/     # YOLO format labels for training
  â”‚   â”œâ”€â”€ test/      # YOLO format labels for testing
  ```
## ğŸ“Š Results

### Faster R-CNN Metrics:
- **AP@25**: 0.62
- **AP@50**: 0.56
- **AP@75**: 0.48
- **Details**: Implemented CBAM attention mechanism and trained with ResNet-50 backbone. Performed well on larger abnormalities like Nodule but faced challenges with smaller regions like Mass.

### YOLOv8 Metrics:
- **Precision**: ~70%
- **Recall**: ~65%
- **mAP@50**: ~0.497
- **mAP@50-95**: ~0.271
- **Details**: Focused on speed and real-time application. Struggled with minority classes but performed robustly on larger, well-represented classes.

### Next Steps:
- Fine-tune both Faster R-CNN and YOLOv8 to address small-region abnormalities.
- Improve dataset balance for minority classes with advanced sampling techniques.

